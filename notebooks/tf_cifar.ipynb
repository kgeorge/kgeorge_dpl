{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cifar-10 training and prediction using tensorflow, simple stuff\n",
    "\n",
    "## koshy george, kgeorge2@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [tensorflow](https://www.tensorflow.org/) to train a convolutional neural net (CNN) net to classify [cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset. \n",
    "\n",
    "There are already enough examples out there to  show how this is done. Two examples are\n",
    "\n",
    "1. [official tensorflow cifar turorial](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/image/cifar10)\n",
    "2. [JeanDut's github page](https://github.com/jeandut/tensorflow-models)\n",
    "\n",
    "We are not here attempting to get the highest accuracy in test images. The objective of this exercise is to have the code in a simplified manner, which does the training.\n",
    "\n",
    "We first tried the [official tensorflow cifar turorial](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/image/cifar10). A beginner at solving image classification problem of [cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html) need to get this done from basic knowledge of CNN and [tensorflow](https://www.tensorflow.org/). But most of the code [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/image/cifar10) employs knowledge of higher level tensorflow functionalities, which a beginner is only struggling to know. [JeanDut's github page](https://github.com/jeandut/tensorflow-models) prooved much more useful to us, when we were stuck. But what follows is mainly our implememtation of this from simple basic principles.\n",
    "\n",
    "Also, our implementation here has got a few additional contributions, (though not necessarily have any direct bearing on either [tensorflow](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/image/cifar10) or deep learning), but, none the less on jupyter notebook technology.\n",
    "\n",
    "1. Our main notebook document (that is this notebook) imports other notebooks which contian common code. Please see [here](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Importing%20Notebooks.html). We use the following set of relative paths. In the example given below, *this_notebook.ipynb* imports *utils.ipynb* as a python module.\n",
    "    * *this_notebook.ipynb*\n",
    "    * *common*\n",
    "        * *utils.ipynb*\n",
    "\n",
    "2. We require [jupyter ipywidgets](https://github.com/ipython/ipywidgets) to be installed before running this notebook and we have written a small custom ipywidget to show incremental progress as training goes. [ipywidget](https://github.com/ipython/ipywidgets) is a small add-on to [jupyter](http://jupyter.org/) technology. You can easily pip install this component once you have installed [jupyter](http://jupyter.org/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us import <code>common/utils.ipynb</code> as a python module. We first amend <code>sys.path</code> to include the relative path which houses the <code>utils.ipynb</code> notebook. We also import the module <code> load_notebooks.ipynb</code> which helps us in loading <code>utils.ipynb</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from common/utils.ipynb\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "require.undef('progress_image');\n",
       "\n",
       "define('progress_image', [\"jupyter-js-widgets\"], function(widgets) {\n",
       "\n",
       "    // Define the HelloView\n",
       "    var ProgressImageView = widgets.DOMWidgetView.extend({\n",
       "        // Render the view.\n",
       "        render: function() {\n",
       "            this.$img = $('<img />')\n",
       "                .appendTo(this.$el);\n",
       "        },\n",
       "        \n",
       "        update: function() {\n",
       "            this.$img.attr('src', this.model.get('value'));\n",
       "            return ProgressImageView.__super__.update.apply(this);\n",
       "        },\n",
       "        events: {\"change\": \"handle_value_change\"},\n",
       "        \n",
       "        handle_value_change: function(event) {\n",
       "            this.model.set('value', this.$img.src);\n",
       "            this.touch();\n",
       "        },\n",
       "        \n",
       "    });\n",
       "\n",
       "    return {\n",
       "        ProgressImageView : ProgressImageView \n",
       "    }\n",
       "});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "#mechanism to dynamically include the relative path where utils.ipynb is housed to the module search path.\n",
    "from inspect import getsourcefile\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import cPickle\n",
    "import urllib, tarfile\n",
    "current_path = os.path.abspath(getsourcefile(lambda:0))\n",
    "parent_dir = os.path.split(os.path.dirname(current_path))[0]\n",
    "sys.path.insert(0, parent_dir)\n",
    "#load_notebooks.py is a module which houses the mechanism to load other notebooks as a python module\n",
    "\n",
    "import common.load_notebooks\n",
    "import common.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Download the cifar data into the data-directory if needed.\n",
    "The data directory is realtively positioned in this example as\n",
    "    * this_notebook.ipynb\n",
    "    * common\n",
    "        * utils.ipynb\n",
    "    * data\n",
    "        * dataset_dir, possible place where the cifar-10-python directory is untarred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully downloaded cifar-10-python.tar.gz 170498071 bytes.\n",
      "./../data/cifar-10-batches-py\n"
     ]
    }
   ],
   "source": [
    "DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "def maybe_download_and_extract(dest_directory):\n",
    "    \"\"\"Download and extract the tarball from Alex's website.\"\"\"\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename,\n",
    "            float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "        filepath, _ = urllib.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.') \n",
    "    with tarfile.open(filepath, 'r:gz') as t:\n",
    "        dataset_dir = os.path.join(dest_directory, t.getmembers()[0].name)\n",
    "        t.extractall(dest_directory)\n",
    "    \n",
    "    return dataset_dir\n",
    "\n",
    "dataset_dir = maybe_download_and_extract('./../data')\n",
    "print(dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below  are the hyper parameters used. We use cifar-10 which consist of images categorized into 10 classes. So <code>n_classes</code> = 10. Our <code>batch_size</code>  which is the number of sample images in a mini-batch is 256. The input images are 3-channel (RGB) images ech of size <code>image_depth x image_height x image_width</code>, where <code>image_height</code> = 32, <code>image_width</code> = 32 and <code>image_depth</code>=3. Our <code>learning_rate</code> is 0.1. We do not employ any learnig rate decay. We use a <code>MomentumOptimizer</code>, with a momentum rate of 0.9. Once we train all images in  the training set, we repeat the training for <code>n_epoch</code>, where <code>n_epoch</code>=30. If epoch number <code>(0:n_epochs)</code> is divisible by <code>n_checkpoint_steps</code>, we save the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "n_classes=10\n",
    "batch_size=256\n",
    "image_width=32\n",
    "image_height=32\n",
    "image_depth=3\n",
    "learning_rate=0.1\n",
    "n_epochs=30\n",
    "#only the first 2000 samples is used for testing\n",
    "n_test_samples=2000\n",
    "n_checkpoint_steps=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the loading of data and labels from the dataset, we expect the following\n",
    "\n",
    "*  <code>train_all['data']</code> is an <code>numpy</code> ndarray of <code>dtype=numpy.float32</code> and  shape <code>(N_train, h, w, d)</code>, where <code>N_train</code>=number of images  in the training set, <code>h=image_height, w=image_width</code> and <code>d=image_depth</code>.\n",
    "\n",
    "*  <code>train_all['labels']</code> is an <code>numpy</code> ndarray of <code>dtype=numpy.int32</code> and  shape = <code>(N_train,)</code>\n",
    "\n",
    "*  <code>test_all['data']</code> is an <code>numpy</code> ndarray of <code>dtype=numpy.float32</code> and  shape <code>(N_test, h, w, d)</code>, where <code>N_test</code>=number of images  used for testing, <code>h=image_height, w=image_width</code> and <code>d=image_depth</code>.\n",
    "\n",
    "*  <code>train_all['labels']</code> is an <code>numpy</code> ndarray of <code>dtype=numpy.int32</code> and  <code>shape = (N_test,)</code>\n",
    "*  <code>N_test = n_test_samples</code>, (ie 2000) only the first 2000 images in the test set is used for testing.\n",
    "* <code>train_all['data']</code>  and <code>test_all['data']</code>  are mean normalized across samples.\n",
    "\n",
    "#### mean-normalization\n",
    "We do not employ any dynamic data-augmentation (which can prevent overfitting). We do not crop the images to any smaller size.  The only transformation that we do is mean-normalization across the dataset. Please note that, the mean normalization is not per-image mean-normalization. We take the data-part (not labels-part) as an N x 3072 float array, and mean-normalize each of the 3072 elements across all images(ie N).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_all:  data:  (50000, 32, 32, 3) float32   labels:  (50000,) int32\n",
      "test_all:  data:  (2000, 32, 32, 3) float32   labels:  (2000,) int32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#regular expression that matches a datafile\n",
    "r_data_file = re.compile('^data_batch_\\d+')\n",
    "\n",
    "#training and test datasets as numpy n-d arrays, \n",
    "#apropriate portions of which are ready to be fed to the placeholder variables\n",
    "train_all={'data':[], 'labels':[]}\n",
    "test_all={'data':[], 'labels':[]}\n",
    "\n",
    "\n",
    "def unpickle(relpath):    \n",
    "    with open(relpath, 'rb') as fp:\n",
    "        d = cPickle.load(fp)\n",
    "    return d\n",
    "\n",
    "def transform_input(data=None, labels=None, h=-1, w=-1, d=-1):\n",
    "    global image_width, image_height, image_depth\n",
    "    assert(data.shape[1] == image_height*image_width*image_depth)\n",
    "    assert(data.shape[0] == labels.shape[0])\n",
    "    data = data.reshape([-1,image_depth, image_height, image_width])\n",
    "    data = data.transpose([0, 2, 3, 1])\n",
    "    data = data.astype(np.float32)\n",
    "    return data, labels\n",
    "\n",
    "def prepare_input(data=None, labels=None):\n",
    "    global image_height, image_width, image_depth\n",
    "    assert(data.shape[1] == image_height * image_width * image_depth)\n",
    "    assert(data.shape[0] == labels.shape[0])\n",
    "    #do mean normaization across all samples\n",
    "    mu = np.mean(data, axis=0)\n",
    "    mu = mu.reshape(1,-1)\n",
    "    sigma = np.std(data, axis=0)\n",
    "    sigma = sigma.reshape(1, -1)\n",
    "    data = data - mu\n",
    "    data = data / sigma\n",
    "    is_nan = np.isnan(data)\n",
    "    is_inf = np.isinf(data)\n",
    "    if np.any(is_nan) or np.any(is_inf):\n",
    "        print('data is not well-formed : is_nan {n}, is_inf: {i}'.format(n= np.any(is_nan), i=np.any(is_inf)))\n",
    "    #data is transformed from (no_of_samples, 3072) to (no_of_samples , image_height, image_width, image_depth)\n",
    "    #make sure the type of the data is no.float32\n",
    "    data = data.reshape([-1,image_depth, image_height, image_width])\n",
    "    data = data.transpose([0, 2, 3, 1])\n",
    "    data = data.astype(np.float32)\n",
    "    return data, labels\n",
    "\n",
    "    #return transform_input(data=data, labels=labels, h=image_height, w=image_width, d=image_depth)\n",
    "\n",
    "\n",
    "def load_and_preprocess_input(dataset_dir=None):\n",
    "    assert(os.path.isdir(dataset_dir))\n",
    "    global train_all, test_all\n",
    "    trn_all_data=[]\n",
    "    trn_all_labels=[]\n",
    "    tst_all_data=[]\n",
    "    tst_all_labels=[]\n",
    "    #for loading train dataset, iterate through the directory to get matchig data file\n",
    "    for root, dirs, files in os.walk(dataset_dir):\n",
    "        for f in files:\n",
    "            m=r_data_file.match(f)\n",
    "            if m:\n",
    "                relpath = os.path.join(root, f)\n",
    "                d=unpickle(os.path.join(root, f))\n",
    "                trn_all_data.append(d['data'])\n",
    "                trn_all_labels.append(d['labels'])\n",
    "    #concatenate all the  data in various files into one ndarray of shape\n",
    "    #data.shape == (no_of_samples, 3072), where 3072=image_depth x image_height x image_width\n",
    "    #labels.shape== (no_of_samples)\n",
    "    trn_all_data, trn_all_labels = (np.concatenate(trn_all_data).astype(np.float32),\n",
    "                                          np.concatenate(trn_all_labels).astype(np.int32)\n",
    "                                        )\n",
    "    \n",
    "    #load the only test data set\n",
    "    #use only the first n_test_samples samples for testing\n",
    "    test_temp=unpickle(os.path.join(dataset_dir, 'test_batch'))\n",
    "    tst_all_data=test_temp['data'][0:n_test_samples, :]\n",
    "    tst_all_labels=test_temp['labels'][0:n_test_samples]\n",
    "    tst_all_data, tst_all_labels =  (np.concatenate([tst_all_data]).astype(np.float32),\n",
    "                                             np.concatenate([tst_all_labels]).astype(np.int32))\n",
    "    #transform the test images in the same manner as the train images\n",
    "                                                             \n",
    "    train_all['data'], train_all['labels'] = prepare_input(data=trn_all_data, labels=trn_all_labels)\n",
    "    test_all['data'], test_all['labels'] = prepare_input(data=tst_all_data, labels=tst_all_labels)\n",
    "    \n",
    "load_and_preprocess_input(dataset_dir=dataset_dir)\n",
    " \n",
    "print('train_all: ', 'data: ', train_all['data'].shape, train_all['data'].dtype,  '  labels: ', train_all['labels'].shape, train_all['labels'].dtype)\n",
    "print('test_all: ', 'data: ', test_all['data'].shape, test_all['data'].dtype,  '  labels: ', test_all['labels'].shape, test_all['labels'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>init_weights</code> is a handy function that constructs a  tensorflow Variable from a set of parameters. We can use this to construct, weights and biases for our network used.\n",
    "\n",
    "<code>wireup</code> accepts the data <code>X</code> as a placeholder and wire-up the model (neural net), returning the variable which is the final output.(logits)\n",
    "\n",
    "<code>compute_loss</compute> computes the cross-entropy between the logits and the label-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#kg: handy general initialization function\n",
    "#\n",
    "def init_weights(shape, init_method='xavier', seed=42, xavier_params = (None, None), const=0.0,  name='', stddev=0.05):\n",
    "    assert(name)\n",
    "    if init_method=='constant':\n",
    "        return tf.get_variable(name, shape, initializer=tf.constant_initializer(const), dtype=tf.float32)\n",
    "    elif init_method == 'uniform':\n",
    "        return tf.Variable(tf.random_normal(shape, stddev=stddev, dtype=tf.float32, seed=seed), name=name)\n",
    "    elif init_method == 'tnormal':\n",
    "        return tf.get_variable(name, shape,  dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=stddev, dtype=tf.float32, seed=seed))\n",
    "        #return tf.Variable(, name=name)\n",
    "    elif init_method=='xavier':\n",
    "        (fan_in, fan_out) = xavier_params\n",
    "        low = -4*np.sqrt(6.0/(fan_in + fan_out))\n",
    "        high = 4*np.sqrt(6.0/(fan_in + fan_out))\n",
    "        return tf.Variable(tf.random_uniform(shape, minval=low, maxval=high, dtype=tf.float32, seed=seed), name=name)\n",
    "\n",
    "\n",
    "def wireup(x, batch_size=256, n_classes=10, scope='dummy'):\n",
    "    with tf.variable_scope(scope) as sc:\n",
    "        #first convolutional layer\n",
    "        weights_initializer_method='tnormal'\n",
    "        c1 = init_weights(shape=[5,5,3, 64], init_method=weights_initializer_method, name='c1')\n",
    "        conv1 = tf.nn.conv2d(x, c1, strides=[1,1,1,1], padding='SAME')\n",
    "        b1 = init_weights(shape=[64], init_method='constant', name='b1')\n",
    "        conv1 = tf.nn.relu(tf.nn.bias_add(conv1, b1), name='conv1')\n",
    "        pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool1')\n",
    "        norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm1')\n",
    "    \n",
    "    \n",
    "        #second convolutional layer\n",
    "        c2 = init_weights(shape=[5,5,64, 64], init_method=weights_initializer_method, name='c2')\n",
    "        conv2 = tf.nn.conv2d(norm1, c2, strides=[1,1,1,1], padding='SAME')\n",
    "        b2 = init_weights(shape=[64], init_method='constant', name='b2', const=0.1)\n",
    "        conv2 = tf.nn.relu(tf.nn.bias_add(conv2, b2), name='conv2')\n",
    "        norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm2')\n",
    "        pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool2')\n",
    "    \n",
    "        reshape = tf.reshape(pool2, [batch_size, -1])\n",
    "        dim = reshape.get_shape()[1].value\n",
    "        #first fully connected layer\n",
    "        fc1= init_weights(shape=[dim, 384], init_method=weights_initializer_method, name='fc1')\n",
    "        bc1= init_weights(shape=[384], init_method='constant', name='bc1', const=0.1)\n",
    "        full1 = tf.nn.relu(tf.matmul(reshape, fc1) + bc1, name='full1')\n",
    "       \n",
    "        #second fully connected layer\n",
    "        fc2= init_weights(shape=[384, 192], init_method=weights_initializer_method, name='fc2')\n",
    "        bc2= init_weights(shape=[192], init_method='constant', name='bc2', const=0.1)\n",
    "        full2 = tf.nn.relu(tf.matmul(full1, fc2) + bc2, name='full2')\n",
    "           \n",
    "        #output layer       \n",
    "        last = init_weights(shape=[192, n_classes], init_method=weights_initializer_method, name='last')\n",
    "        b_last = init_weights(shape=[n_classes], init_method='constant', name='b_last')\n",
    "        logits = tf.add(tf.matmul(full2, last), b_last, name='final')\n",
    "    return logits\n",
    "\n",
    "def compute_loss(logits, labels):\n",
    "    print('compute_loss: {lg}, {lb}'.format(lg=logits.get_shape(), lb=labels.get_shape()))\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "      logits, labels, name='cross_entropy_per_example')\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "    return cross_entropy_mean\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GUI support for progress display\n",
    "For displaying progress as an incrementally updating matplotlib plot, we employ the custom [ipywidget](https://github.com/ipython/ipywidgets) , defined at <code>common/utils.ipynb</code> called <code>ProgressImageWidget</code>. We need two graphs, one for plotting training loss acros epoch-s and the other for plotting accuracy of training and test data across epochs. We enclose the two <code>ProgressImageWidget</code>-s in a [ipywidget](https://github.com/ipython/ipywidgets)  VBox.\n",
    "\n",
    "<code>ProgressImageWidget</code> will display any image assigned to its <code>value</code>, if the image is a [datauri](https://en.wikipedia.org/wiki/Data_URI_scheme) string. \n",
    "\n",
    "<code>\n",
    "p=common.utils.ProgressImageWidget()\n",
    "display(p)\n",
    "</code>\n",
    "\n",
    "\n",
    "..., lots of stuff\n",
    "\n",
    "\n",
    "Now if if you assign the value element of <code>p</code> to some new image content, the widget displayed by the display  call above, will now have the new image content.\n",
    "<code>\n",
    "p.value = new_image_content_as_png_dataurl\n",
    "</code>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "p_loss=common.utils.ProgressImageWidget()\n",
    "p_acc=common.utils.ProgressImageWidget()\n",
    "top_level=widgets.VBox(children=[p_loss, p_acc])\n",
    "display(top_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GUI support for progress display, contd\n",
    "\n",
    "Now for constructing the [datauri](https://en.wikipedia.org/wiki/Data_URI_scheme), which shows the progress graph, we employ another helper class called <code>Plotter</code> defined in <code>common/utils.ipynb</code>. We can construct a plotter with <code>xlabel, ylabel</code> and <code>title</code> parameters. An instance of a potter class, will return a png-datauri when the <code>plotter.plot()</code> is called.\n",
    "\n",
    "We can also add many channels to the plot. For each channel we must supply an upperboumd on the number of samples that will be added to the channel. See <code>Plotter.add_channel</code>. All the channels will be shown on the same plot.\n",
    "\n",
    "We should add as many samples to each channel as we please and if you call <code>plotter.plot()</code>, a pong datauri containing the plot will be returned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#for displaying the training loss\n",
    "plotter_loss = common.utils.Plotter(xlabel='no. of epochs', ylabel='loss', title='epochs')\n",
    "plotter_loss.add_channel(num_samples=n_epochs, channel_name='train_loss', legend='train_loss')\n",
    "\n",
    "#for displaying the training and test accuracy, in the sample plot\n",
    "plotter_acc = common.utils.Plotter(xlabel='no. of epochs', ylabel='acc', title='epochs')\n",
    "plotter_acc.add_channel(num_samples=n_epochs, channel_name='train_acc',legend='train_acc')\n",
    "plotter_acc.add_channel(num_samples=n_epochs, channel_name='test_acc', legend='test_acc')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_loss: (256, 10), (256, 10)\n",
      "starting training\n",
      "loss for epoch 0, train_loss=1.66669226487,  test-accuracy=0.494977678571,  time=37.5025420189\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Graph().as_default():\n",
    "    X = tf.placeholder(tf.float32, shape=(batch_size, image_height, image_width, image_depth))\n",
    "    y = tf.placeholder(tf.float32, shape=(batch_size, 10))\n",
    "    \n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    logits=wireup(X, batch_size=batch_size, n_classes=10, scope='train')\n",
    "    loss = compute_loss(logits, y)\n",
    "    optimizer=tf.train.MomentumOptimizer(learning_rate,0.9).minimize(loss,global_step) \n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    accuracy_1 = tf.equal(tf.argmax(train_prediction, 1), tf.argmax(y, 1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(accuracy_1,tf.float32),0)\n",
    "    \n",
    "    init = tf.initialize_all_variables()\n",
    "    n_batches_train = int(train_all['labels'].shape[0]//batch_size)\n",
    "    n_batches_test = int(test_all['labels'].shape[0]//batch_size)\n",
    "    \n",
    "    def checkpoint():\n",
    "        global dataset_dir\n",
    "        dataset_name = os.path.split(dataset_dir)[1]\n",
    "        if not os.path.isdir(os.path.join(dataset_dir, 'out')):\n",
    "            os.makedirs(os.path.join(dataset_dir, 'out'))\n",
    "        loss_fig_path= os.path.join(dataset_dir, 'out', '%s_train_loss.png' % dataset_name)\n",
    "        acc_fig_path= os.path.join(dataset_dir, 'out', '%s_acc.png' % dataset_name)\n",
    "        plotter_loss.plot_and_save_fig(savepath=loss_fig_path)\n",
    "        plotter_acc.plot_and_save_fig(savepath=acc_fig_path)\n",
    "        \n",
    "    def all_batches_run_train(n_batches, data=None, labels=None):\n",
    "        sum_all_batches_loss =0\n",
    "        sum_all_batches_acc=0\n",
    "        sum_n_samples=0\n",
    "        for b in xrange(n_batches):            \n",
    "                offset = b * batch_size\n",
    "                batch_data = data[offset : offset+batch_size, :, :, :]\n",
    "                n_samples = batch_data.shape[0]\n",
    "                batch_labels = labels[offset: offset+batch_size]\n",
    "                batch_labels = (np.arange(n_classes) == batch_labels[:, None]).astype(np.float32)\n",
    "                feed_dict = {X: batch_data, \n",
    "                             y: batch_labels}\n",
    "                _, loss_value, a = sess.run([optimizer, loss, accuracy], feed_dict=feed_dict)\n",
    "                sum_all_batches_loss += loss_value * n_samples\n",
    "                sum_all_batches_acc += a * n_samples\n",
    "                sum_n_samples += n_samples\n",
    "                if(n_samples != batch_size):\n",
    "                    print('n_samples =%d' % n_samples)\n",
    "        return sum_all_batches_loss/sum_n_samples, sum_all_batches_acc/sum_n_samples\n",
    "    \n",
    "    def all_batches_run_test(n_batches, data=None, labels=None):\n",
    "        sum_all_batches_acc=0\n",
    "        sum_n_samples=0\n",
    "        for b in xrange(n_batches):\n",
    "                offset = b * batch_size\n",
    "                batch_data = data[offset : offset+batch_size, :, :, :]\n",
    "                n_samples = batch_data.shape[0]\n",
    "                batch_labels = labels[offset: offset+batch_size]\n",
    "                batch_labels = (np.arange(n_classes) == batch_labels[:, None]).astype(np.float32)\n",
    "                feed_dict = {X: batch_data, \n",
    "                             y: batch_labels}\n",
    "                a = sess.run([accuracy], feed_dict=feed_dict)\n",
    "                sum_all_batches_acc += a[0] * n_samples\n",
    "                sum_n_samples += n_samples\n",
    "                if(n_samples != batch_size):\n",
    "                    print('n_samples =%d' % n_samples)\n",
    "        return sum_all_batches_acc/sum_n_samples\n",
    "                    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        print('starting training')\n",
    "        \n",
    "        \n",
    "        for e in xrange(n_epochs):\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            sum_loss_train=0\n",
    "            sum_samples_train =0\n",
    "            sum_acc_train=0\n",
    "            n_data = train_all['data'].shape[0]\n",
    "            \n",
    "            perm = np.random.permutation(n_data)\n",
    "            permuted_data = train_all['data'][perm,:, :, :]\n",
    "            permuted_labels = train_all['labels'][perm]\n",
    "            \n",
    "            test_data = test_all['data']\n",
    "            test_labels = test_all['labels']\n",
    "            \n",
    "            mean_loss_per_sample_train, accuracy_per_sample_train=all_batches_run_train(n_batches_train, data=permuted_data, labels=permuted_labels)\n",
    "            accuracy_per_sample_test=all_batches_run_test(n_batches_test, data=test_data, labels=test_labels)\n",
    "     \n",
    "            plotter_loss.add_sample( e, mean_loss_per_sample_train , channel_name='train_loss')\n",
    "            plotter_acc.add_sample( e, accuracy_per_sample_train, channel_name='train_acc')\n",
    "            plotter_acc.add_sample( e, accuracy_per_sample_test, channel_name='test_acc')\n",
    "            sum_acc_test=0\n",
    "            sum_samples_test=0\n",
    "            p_loss.value = plotter_loss.plot()\n",
    "            p_acc.value = plotter_acc.plot()\n",
    "            duration = time.time() - start_time\n",
    "            if (e% n_checkpoint_steps) == 0:\n",
    "                print('loss for epoch {e}, train_loss={l},  test-accuracy={a},  time={t}'.format(e=e, l=mean_loss_per_sample_train, a=accuracy_per_sample_test, t=duration))\n",
    "                checkpoint()\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "ba6516b9c5264c22ab12f7549bc15810": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
